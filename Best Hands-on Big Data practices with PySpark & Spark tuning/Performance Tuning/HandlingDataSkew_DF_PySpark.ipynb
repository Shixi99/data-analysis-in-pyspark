{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SZ-oubpyQTV7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Shixi-KK46BQG:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dealing with skewd data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Dealing with skewd data>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "conf = SparkConf()\\\n",
    "    .setMaster(\"local[*]\")\\\n",
    "    .setAppName(\"Dealing with skewd data\")\n",
    "    # .setExecutorEnv(\"spark.driver.memory\",\"2g\")\\\n",
    "    # .setExecutorEnv(\"spark.executor.memory\",\"4g\")\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(conf=conf)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5gSD3YVQTV9"
   },
   "source": [
    "# (1) Loading Data Skew\n",
    "\n",
    "To understand skew, we create a random data where keys are uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# sale dataset:\n",
    "# table 1: OrderID, Qty, Sales, Discount (yes=1, no=0)\n",
    "# table 2: ProductID, OrderID, Product, Price\n",
    "\n",
    "########### Table 1 ###########\n",
    "\n",
    "key_1 = [101] * 100 #1 #100\n",
    "key_2 = [201] * 7000000 #8 #7000000\n",
    "key_3 = [301] * 500 #4 #500\n",
    "key_4 = [401] * 10000 #2 #10000\n",
    "OrderID = key_1 + key_2 + key_3 + key_4\n",
    "random.shuffle(OrderID)\n",
    "\n",
    "Qty_1 = list(np.random.randint(low = 1, high = 100, size = len(key_1)))\n",
    "Qty_2 = list(np.random.randint(low = 1, high = 200, size = len(key_2)))\n",
    "Qty_3 = list(np.random.randint(low = 1, high = 1000, size = len(key_3)))\n",
    "Qty_4 = list(np.random.randint(low = 1, high = 50, size = len(key_4)))\n",
    "Qty = Qty_1 + Qty_2 + Qty_3 + Qty_4\n",
    "\n",
    "Sales_1 = list(np.random.randint(low = 10, high = 100, size = len(key_1)))\n",
    "Sales_2 = list(np.random.randint(low = 50, high = 3400, size = len(key_2)))\n",
    "Sales_3 = list(np.random.randint(low = 12, high = 2000, size = len(key_3)))\n",
    "Sales_4 = list(np.random.randint(low = 40, high = 1000, size = len(key_4)))\n",
    "Sales = Sales_1 + Sales_2 + Sales_3 + Sales_4\n",
    "\n",
    "Discount = list(np.random.randint(low = 0, high = 2, size = len(OrderID)))\n",
    "data1 = list(zip(OrderID,Qty,Sales,Discount))\n",
    "\n",
    "# Create the Pandas DF\n",
    "data_skew = pd.DataFrame(data1, columns=['OrderID','Qty','Sales','Discount'])\n",
    "\n",
    "\n",
    "########### Table 2 ###########\n",
    "data2 = [[1, 101, 'pencil', 4.99],\n",
    "         [2, 101, 'book', 9.5],\n",
    "         [3, 101, 'scissors', 14],\n",
    "         [4, 301, 'glue', 7],\n",
    "         [5, 201, 'marker', 8.49],\n",
    "         [6, 301, 'label', 2],\n",
    "         [7, 201, 'calculator', 3.99],\n",
    "         [8, 501, 'eraser', 1.55],\n",
    "        ]\n",
    "\n",
    "data_small = pd.DataFrame(data2, columns=['ProductID', 'OrderID', 'Product', 'Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderID: long (nullable = true)\n",
      " |-- Qty: long (nullable = true)\n",
      " |-- Sales: long (nullable = true)\n",
      " |-- Discount: long (nullable = true)\n",
      "\n",
      "+-------+---+-----+--------+\n",
      "|OrderID|Qty|Sales|Discount|\n",
      "+-------+---+-----+--------+\n",
      "|    201|  4|   17|       1|\n",
      "|    201| 93|   95|       0|\n",
      "|    201| 36|   23|       0|\n",
      "|    201| 28|   68|       0|\n",
      "|    201| 75|   37|       1|\n",
      "|    201| 36|   13|       0|\n",
      "|    201| 89|   28|       1|\n",
      "|    201| 86|   28|       1|\n",
      "|    201| 99|   64|       1|\n",
      "|    201| 92|   67|       1|\n",
      "|    201|  1|   82|       0|\n",
      "|    201|  7|   94|       0|\n",
      "|    201| 52|   62|       0|\n",
      "|    201| 95|   85|       1|\n",
      "|    201| 95|   62|       0|\n",
      "|    201| 61|   63|       1|\n",
      "|    201| 43|   21|       1|\n",
      "|    201| 14|   86|       1|\n",
      "|    201| 56|   73|       1|\n",
      "|    201| 20|   48|       0|\n",
      "|    201| 24|   10|       0|\n",
      "|    201| 77|   34|       0|\n",
      "|    201|  8|   36|       0|\n",
      "|    201| 18|   62|       0|\n",
      "|    201| 66|   93|       0|\n",
      "|    201| 59|   65|       0|\n",
      "|    201| 78|   32|       1|\n",
      "|    201| 58|   37|       0|\n",
      "|    201| 36|   66|       0|\n",
      "|    201| 27|   39|       0|\n",
      "+-------+---+-----+--------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create PySpark DF from Pandas\n",
    "\n",
    "# Optimize conversion between PySpark and Pandas DF: Enable arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "df_skew = spark.createDataFrame(data_skew)\n",
    "df_skew.printSchema()\n",
    "df_skew.show(30)\n",
    "df_skew.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ProductID: long (nullable = true)\n",
      " |-- OrderID: long (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n",
      "+---------+-------+----------+-----+\n",
      "|ProductID|OrderID|   Product|Price|\n",
      "+---------+-------+----------+-----+\n",
      "|        1|    101|    pencil| 4.99|\n",
      "|        2|    101|      book|  9.5|\n",
      "|        3|    101|  scissors| 14.0|\n",
      "|        4|    301|      glue|  7.0|\n",
      "|        5|    201|    marker| 8.49|\n",
      "|        6|    301|     label|  2.0|\n",
      "|        7|    201|calculator| 3.99|\n",
      "|        8|    501|    eraser| 1.55|\n",
      "+---------+-------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = spark.createDataFrame(data_small)\n",
    "df_small.printSchema()\n",
    "df_small.show(30)\n",
    "df_small.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Run a shuffle `Join()` with small sized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "|OrderID|Qty|Sales|Discount|ProductID|OrderID|   Product|Price|\n",
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "|    201| 95|  698|       1|        5|    201|    marker| 8.49|\n",
      "|    201| 95|  698|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 56|  330|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 56|  330|       0|        7|    201|calculator| 3.99|\n",
      "|    201|170|  351|       1|        5|    201|    marker| 8.49|\n",
      "|    201|170|  351|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 45| 3223|       1|        5|    201|    marker| 8.49|\n",
      "|    201| 45| 3223|       1|        7|    201|calculator| 3.99|\n",
      "|    201|443|  229|       1|        5|    201|    marker| 8.49|\n",
      "|    201|443|  229|       1|        7|    201|calculator| 3.99|\n",
      "|    201|415|  176|       1|        5|    201|    marker| 8.49|\n",
      "|    201|415|  176|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 13|  808|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 13|  808|       0|        7|    201|calculator| 3.99|\n",
      "|    201| 45|  734|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 45|  734|       0|        7|    201|calculator| 3.99|\n",
      "|    301| 72|   60|       0|        4|    301|      glue|  7.0|\n",
      "|    301| 72|   60|       0|        6|    301|     label|  2.0|\n",
      "|    301|135| 1755|       0|        4|    301|      glue|  7.0|\n",
      "|    301|135| 1755|       0|        6|    301|     label|  2.0|\n",
      "|    301| 21| 1217|       0|        4|    301|      glue|  7.0|\n",
      "|    301| 21| 1217|       0|        6|    301|     label|  2.0|\n",
      "|    301|755|  529|       0|        4|    301|      glue|  7.0|\n",
      "|    301|755|  529|       0|        6|    301|     label|  2.0|\n",
      "|    101| 34|  579|       0|        1|    101|    pencil| 4.99|\n",
      "|    101| 34|  579|       0|        2|    101|      book|  9.5|\n",
      "|    101| 34|  579|       0|        3|    101|  scissors| 14.0|\n",
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = df_skew.join(df_small, df_skew.OrderID == df_small.OrderID, how = 'inner')\n",
    "\n",
    "joined_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Row(OrderID=201, Qty=95, Sales=698, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=95, Sales=698, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=56, Sales=330, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=56, Sales=330, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=170, Sales=351, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=170, Sales=351, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=45, Sales=3223, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=45, Sales=3223, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=443, Sales=229, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=443, Sales=229, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=415, Sales=176, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=415, Sales=176, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=13, Sales=808, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=13, Sales=808, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=45, Sales=734, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=45, Sales=734, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Row(OrderID=301, Qty=72, Sales=60, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=72, Sales=60, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=135, Sales=1755, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=135, Sales=1755, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=21, Sales=1217, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=21, Sales=1217, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=755, Sales=529, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=755, Sales=529, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=1, OrderID=101, Product='pencil', Price=4.99),\n",
       "  Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=2, OrderID=101, Product='book', Price=9.5),\n",
       "  Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=3, OrderID=101, Product='scissors', Price=14.0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(joined_df.rdd.getNumPartitions())\n",
    "joined_df.rdd.glom().collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration is used to specify the default number partitions when shuffles data for aggregations or joins. The default value is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "|OrderID|Qty|Sales|Discount|ProductID|OrderID|   Product|Price|\n",
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "|    201| 95|  698|       1|        5|    201|    marker| 8.49|\n",
      "|    201| 95|  698|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 56|  330|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 56|  330|       0|        7|    201|calculator| 3.99|\n",
      "|    201|170|  351|       1|        5|    201|    marker| 8.49|\n",
      "|    201|170|  351|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 45| 3223|       1|        5|    201|    marker| 8.49|\n",
      "|    201| 45| 3223|       1|        7|    201|calculator| 3.99|\n",
      "|    201|443|  229|       1|        5|    201|    marker| 8.49|\n",
      "|    201|443|  229|       1|        7|    201|calculator| 3.99|\n",
      "|    201|415|  176|       1|        5|    201|    marker| 8.49|\n",
      "|    201|415|  176|       1|        7|    201|calculator| 3.99|\n",
      "|    201| 13|  808|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 13|  808|       0|        7|    201|calculator| 3.99|\n",
      "|    201| 45|  734|       0|        5|    201|    marker| 8.49|\n",
      "|    201| 45|  734|       0|        7|    201|calculator| 3.99|\n",
      "|    301| 72|   60|       0|        4|    301|      glue|  7.0|\n",
      "|    301| 72|   60|       0|        6|    301|     label|  2.0|\n",
      "|    301|135| 1755|       0|        4|    301|      glue|  7.0|\n",
      "|    301|135| 1755|       0|        6|    301|     label|  2.0|\n",
      "|    301| 21| 1217|       0|        4|    301|      glue|  7.0|\n",
      "|    301| 21| 1217|       0|        6|    301|     label|  2.0|\n",
      "|    301|755|  529|       0|        4|    301|      glue|  7.0|\n",
      "|    301|755|  529|       0|        6|    301|     label|  2.0|\n",
      "|    101| 34|  579|       0|        1|    101|    pencil| 4.99|\n",
      "|    101| 34|  579|       0|        2|    101|      book|  9.5|\n",
      "|    101| 34|  579|       0|        3|    101|  scissors| 14.0|\n",
      "+-------+---+-----+--------+---------+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = df_skew.join(df_small, df_skew.OrderID == df_small.OrderID, how = 'inner')\n",
    "\n",
    "joined_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[Row(OrderID=201, Qty=95, Sales=698, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=95, Sales=698, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=56, Sales=330, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=56, Sales=330, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=170, Sales=351, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=170, Sales=351, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=45, Sales=3223, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=45, Sales=3223, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=443, Sales=229, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=443, Sales=229, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=415, Sales=176, Discount=1, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=415, Sales=176, Discount=1, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=13, Sales=808, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=13, Sales=808, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99),\n",
       "  Row(OrderID=201, Qty=45, Sales=734, Discount=0, ProductID=5, OrderID=201, Product='marker', Price=8.49),\n",
       "  Row(OrderID=201, Qty=45, Sales=734, Discount=0, ProductID=7, OrderID=201, Product='calculator', Price=3.99)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Row(OrderID=301, Qty=72, Sales=60, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=72, Sales=60, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=135, Sales=1755, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=135, Sales=1755, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=21, Sales=1217, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=21, Sales=1217, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0),\n",
       "  Row(OrderID=301, Qty=755, Sales=529, Discount=0, ProductID=4, OrderID=301, Product='glue', Price=7.0),\n",
       "  Row(OrderID=301, Qty=755, Sales=529, Discount=0, ProductID=6, OrderID=301, Product='label', Price=2.0)],\n",
       " [Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=1, OrderID=101, Product='pencil', Price=4.99),\n",
       "  Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=2, OrderID=101, Product='book', Price=9.5),\n",
       "  Row(OrderID=101, Qty=34, Sales=579, Discount=0, ProductID=3, OrderID=101, Product='scissors', Price=14.0)],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(joined_df.rdd.getNumPartitions())\n",
    "joined_df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----------------+\n",
      "|  avg|min| max|           stdev|\n",
      "+-----+---+----+----------------+\n",
      "|813.0| 60|3223|822.824746894844|\n",
      "+-----+---+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# descriptive stats\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "groups = df_skew.join(df_small, df_skew.OrderID == df_small.OrderID, how = 'inner')\n",
    "\n",
    "summary = groups.select(\n",
    "    f.round(f.mean(groups.Sales)).alias('avg'),\n",
    "    f.min(groups.Sales).alias('min'),\n",
    "    f.max(groups.Sales).alias('max'),\n",
    "    f.stddev(groups.Sales).alias('stdev')\n",
    ")\n",
    "\n",
    "summary.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate data skewness: SALTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+--------+------+\n",
      "|OrderID|Qty|Sales|Discount|_salt_|\n",
      "+-------+---+-----+--------+------+\n",
      "|    301| 72|   60|       0|   1.0|\n",
      "|    401|126| 2598|       0|   2.0|\n",
      "|    201| 95|  698|       1|   1.0|\n",
      "|    201| 56|  330|       0|   1.0|\n",
      "|    101| 34|  579|       0|   1.0|\n",
      "|    201|170|  351|       1|   0.0|\n",
      "|    301|135| 1755|       0|   1.0|\n",
      "|    301| 21| 1217|       0|   0.0|\n",
      "|    201| 45| 3223|       1|   2.0|\n",
      "|    401| 60| 1864|       0|   2.0|\n",
      "|    201|443|  229|       1|   2.0|\n",
      "|    301|755|  529|       0|   1.0|\n",
      "|    201|415|  176|       1|   2.0|\n",
      "|    201| 13|  808|       0|   1.0|\n",
      "|    201| 45|  734|       0|   1.0|\n",
      "+-------+---+-----+--------+------+\n",
      "\n",
      "+---------+-------+----------+-----+------+\n",
      "|ProductID|OrderID|   Product|Price|_salt_|\n",
      "+---------+-------+----------+-----+------+\n",
      "|        1|    101|    pencil| 4.99|   2.0|\n",
      "|        2|    101|      book|  9.5|   1.0|\n",
      "|        3|    101|  scissors| 14.0|   1.0|\n",
      "|        4|    301|      glue|  7.0|   1.0|\n",
      "|        5|    201|    marker| 8.49|   0.0|\n",
      "|        6|    301|     label|  2.0|   1.0|\n",
      "|        7|    201|calculator| 3.99|   0.0|\n",
      "|        8|    501|    eraser| 1.55|   1.0|\n",
      "+---------+-------+----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f \n",
    "\n",
    "# add random value between [0,2]\n",
    "df_skew_salting = df_skew.withColumn(\"_salt_\", f.round(f.rand() * 2))\n",
    "df_small_salting = df_small.withColumn(\"_salt_\", f.round(f.rand() * 2))\n",
    "\n",
    "df_skew_salting.show()\n",
    "df_small_salting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repartition using _salt_\n",
    "df_skew_salting = df_skew_salting.repartition(3, \"_salt_\")\n",
    "df_small_salting = df_small_salting.repartition(3, \"_salt_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(OrderID=401, Qty=126, Sales=2598, Discount=0, _salt_=2.0),\n",
       "  Row(OrderID=201, Qty=45, Sales=3223, Discount=1, _salt_=2.0),\n",
       "  Row(OrderID=401, Qty=60, Sales=1864, Discount=0, _salt_=2.0),\n",
       "  Row(OrderID=201, Qty=443, Sales=229, Discount=1, _salt_=2.0),\n",
       "  Row(OrderID=201, Qty=415, Sales=176, Discount=1, _salt_=2.0)],\n",
       " [Row(OrderID=201, Qty=170, Sales=351, Discount=1, _salt_=0.0),\n",
       "  Row(OrderID=301, Qty=21, Sales=1217, Discount=0, _salt_=0.0)],\n",
       " [Row(OrderID=301, Qty=72, Sales=60, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=201, Qty=95, Sales=698, Discount=1, _salt_=1.0),\n",
       "  Row(OrderID=201, Qty=56, Sales=330, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=101, Qty=34, Sales=579, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=301, Qty=135, Sales=1755, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=301, Qty=755, Sales=529, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=201, Qty=13, Sales=808, Discount=0, _salt_=1.0),\n",
       "  Row(OrderID=201, Qty=45, Sales=734, Discount=0, _salt_=1.0)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew_salting.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(ProductID=1, OrderID=101, Product='pencil', Price=4.99, _salt_=2.0)],\n",
       " [Row(ProductID=5, OrderID=201, Product='marker', Price=8.49, _salt_=0.0),\n",
       "  Row(ProductID=7, OrderID=201, Product='calculator', Price=3.99, _salt_=0.0)],\n",
       " [Row(ProductID=2, OrderID=101, Product='book', Price=9.5, _salt_=1.0),\n",
       "  Row(ProductID=3, OrderID=101, Product='scissors', Price=14.0, _salt_=1.0),\n",
       "  Row(ProductID=4, OrderID=301, Product='glue', Price=7.0, _salt_=1.0),\n",
       "  Row(ProductID=6, OrderID=301, Product='label', Price=2.0, _salt_=1.0),\n",
       "  Row(ProductID=8, OrderID=501, Product='eraser', Price=1.55, _salt_=1.0)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_salting.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----------------+\n",
      "|  avg|min| max|           stdev|\n",
      "+-----+---+----+----------------+\n",
      "|813.0| 60|3223|822.824746894844|\n",
      "+-----+---+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_skew_salting.drop('_salt_')\n",
    "df_small_salting.drop('_salt_')\n",
    "\n",
    "groups = df_skew_salting.join(df_small_salting, df_skew_salting.OrderID == df_small_salting.OrderID, how = 'inner')\n",
    "\n",
    "summary = groups.select(\n",
    "    f.round(f.mean(groups.Sales)).alias('avg'),\n",
    "    f.min(groups.Sales).alias('min'),\n",
    "    f.max(groups.Sales).alias('max'),\n",
    "    f.stddev(groups.Sales).alias('stdev')\n",
    ")\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igjn1lrUQTWG"
   },
   "source": [
    "# (3) Run a shuffle `Join()` to see how the skew effects computation resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+-----------------+\n",
      "|   avg|min| max|            stdev|\n",
      "+------+---+----+-----------------+\n",
      "|1723.0| 10|3399|967.5906776265002|\n",
      "+------+---+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 8)\n",
    "groups = df_skew.join(df_small, df_skew.OrderID == df_small.OrderID, how = 'inner')\n",
    "\n",
    "summary = groups.select(\n",
    "    f.round(f.mean(groups.Sales)).alias('avg'),\n",
    "    f.min(groups.Sales).alias('min'),\n",
    "    f.max(groups.Sales).alias('max'),\n",
    "    f.stddev(groups.Sales).alias('stdev')\n",
    ")\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate data skewness: SALTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+-----------------+\n",
      "|   avg|min| max|            stdev|\n",
      "+------+---+----+-----------------+\n",
      "|1723.0| 10|3399|967.7618105077845|\n",
      "+------+---+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 8)\n",
    "\n",
    "\n",
    "# add random value between [0,2]\n",
    "df_skew_salting = df_skew.withColumn(\"_salt_\", f.round(f.rand() * 7))\n",
    "df_small_salting = df_small.withColumn(\"_salt_\", f.round(f.rand() * 7))\n",
    "\n",
    "# # repartition using _salt_\n",
    "df_skew_salting = df_skew_salting.repartition(8, \"_salt_\")\n",
    "df_small_salting = df_small_salting.repartition(8, \"_salt_\")\n",
    "\n",
    "df_skew_salting.drop('_salt_')\n",
    "df_small_salting.drop('_salt_')\n",
    "\n",
    "groups = df_skew_salting.join(df_small_salting, df_skew_salting.OrderID == df_small_salting.OrderID, how = 'inner')\n",
    "\n",
    "summary = groups.select(\n",
    "    f.round(f.mean(groups.Sales)).alias('avg'),\n",
    "    f.min(groups.Sales).alias('min'),\n",
    "    f.max(groups.Sales).alias('max'),\n",
    "    f.stddev(groups.Sales).alias('stdev')\n",
    ")\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate data skewness: Broadcast Hash Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+----------------+\n",
      "|   avg|min| max|           stdev|\n",
      "+------+---+----+----------------+\n",
      "|1723.0| 10|3399|967.590677626551|\n",
      "+------+---+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 8)\n",
    "\n",
    "groups_brd = df_skew.join(f.broadcast(df_small), df_skew.OrderID == df_small.OrderID, how = 'inner')\n",
    "\n",
    "summary = groups_brd.select(\n",
    "    f.round(f.mean(groups_brd.Sales)).alias('avg'),\n",
    "    f.min(groups_brd.Sales).alias('min'),\n",
    "    f.max(groups_brd.Sales).alias('max'),\n",
    "    f.stddev(groups_brd.Sales).alias('stdev')\n",
    ")\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DataSkew_RDD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b785a0a06e2d7a312a57a7dba8bbee97b75bb74680ea935274a48dc11f29425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
