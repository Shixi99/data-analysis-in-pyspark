{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "\n",
    "conf = SparkConf()\\\n",
    "    .setMaster('local[*]')\\\n",
    "    .setAppName('Json data with DF')\\\n",
    "    .setExecutorEnv('spark.driver.memory','2g')\\\n",
    "    .setExecutorEnv('spark.executor.memory','4g')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### data source: https://www.kaggle.com/datasets/Cornell-University/arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('arxiv-metadata-oai-snapshot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- authors_parsed: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- journal-ref: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- report-no: string (nullable = true)\n",
      " |-- submitter: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a new Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(authors,StringType,true),StructField(categories,StringType,true),StructField(license,StringType,true),StructField(comments,StringType,true),StructField(abstract,StringType,true),StructField(versions,ArrayType(StringType,true),true)))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, ArrayType, StringType\n",
    "\n",
    "manual_schema = StructType([\n",
    "    StructField('authors', StringType(), True),\n",
    "    StructField('categories', StringType(), True),\n",
    "    StructField('license', StringType(), True),\n",
    "    StructField('comments', StringType(), True),\n",
    "    StructField('abstract', StringType(), True),\n",
    "    StructField('versions', ArrayType(StringType()), True)\n",
    "])\n",
    "\n",
    "print(manual_schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Binding data to a manual schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('arxiv-metadata-oai-snapshot.json',\n",
    "                    schema = manual_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authors: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             authors|       categories|             license|            comments|            abstract|            versions|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|C. Bal\\'azs, E. L...|           hep-ph|                null|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
      "|Ileana Streinu an...|    math.CO cs.CG|http://arxiv.org/...|To appear in Grap...|  We describe a n...|[{\"version\":\"v1\",...|\n",
      "|         Hongjun Pan|   physics.gen-ph|                null| 23 pages, 3 figures|  The evolution o...|[{\"version\":\"v1\",...|\n",
      "|        David Callan|          math.CO|                null|            11 pages|  We show that a ...|[{\"version\":\"v1\",...|\n",
      "|Wael Abu-Shammala...|  math.CA math.FA|                null|                null|  In this paper w...|[{\"version\":\"v1\",...|\n",
      "|Y. H. Pong and C....|cond-mat.mes-hall|                null|6 pages, 4 figure...|  We study the tw...|[{\"version\":\"v1\",...|\n",
      "|Alejandro Corichi...|            gr-qc|                null|16 pages, no figu...|  A rather non-st...|[{\"version\":\"v1\",...|\n",
      "|     Damian C. Swift|cond-mat.mtrl-sci|http://arxiv.org/...|   Minor corrections|  A general formu...|[{\"version\":\"v1\",...|\n",
      "|Paul Harvey, Brun...|         astro-ph|                null|                null|  We discuss the ...|[{\"version\":\"v1\",...|\n",
      "|  Sergei Ovchinnikov|          math.CO|                null|36 pages, 17 figures|  Partial cubes a...|[{\"version\":\"v1\",...|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Missing values for 'comments' ans 'license' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "df = df.dropna(subset=['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace\n",
    "df = df.fillna(value='unknown', subset=['license'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             authors|       categories|             license|            comments|            abstract|            versions|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|C. Bal\\'azs, E. L...|           hep-ph|             unknown|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
      "|Ileana Streinu an...|    math.CO cs.CG|http://arxiv.org/...|To appear in Grap...|  We describe a n...|[{\"version\":\"v1\",...|\n",
      "|         Hongjun Pan|   physics.gen-ph|             unknown| 23 pages, 3 figures|  The evolution o...|[{\"version\":\"v1\",...|\n",
      "|        David Callan|          math.CO|             unknown|            11 pages|  We show that a ...|[{\"version\":\"v1\",...|\n",
      "|Y. H. Pong and C....|cond-mat.mes-hall|             unknown|6 pages, 4 figure...|  We study the tw...|[{\"version\":\"v1\",...|\n",
      "|Alejandro Corichi...|            gr-qc|             unknown|16 pages, no figu...|  A rather non-st...|[{\"version\":\"v1\",...|\n",
      "|     Damian C. Swift|cond-mat.mtrl-sci|http://arxiv.org/...|   Minor corrections|  A general formu...|[{\"version\":\"v1\",...|\n",
      "|  Sergei Ovchinnikov|          math.CO|             unknown|36 pages, 17 figures|  Partial cubes a...|[{\"version\":\"v1\",...|\n",
      "|Clifton Cunningha...|  math.NT math.AG|http://arxiv.org/...|14 pages; title c...|  In this paper w...|[{\"version\":\"v1\",...|\n",
      "|        Koichi Fujii|  math.CA math.AT|             unknown|  18 pages, 1 figure|  In this article...|[{\"version\":\"v1\",...|\n",
      "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get the author names who published a paper in a math category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374379"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "df.filter(sf.col('categories').contains('math')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             authors|\n",
      "+--------------------+\n",
      "|Ileana Streinu an...|\n",
      "|        David Callan|\n",
      "|  Sergei Ovchinnikov|\n",
      "|Clifton Cunningha...|\n",
      "|        Koichi Fujii|\n",
      "|         Norio Konno|\n",
      "|Simon J.A. Malham...|\n",
      "|Robert P. C. de M...|\n",
      "|  P\\'eter E. Frenkel|\n",
      "|          Mihai Popa|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "374379\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('d_archive')\n",
    "\n",
    "query = '''\n",
    "    select authors from d_archive\n",
    "    where categories like '%math%'\n",
    "'''\n",
    "spark.sql(query).show(10)\n",
    "print(spark.sql(query).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374379"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.categories.contains('math')).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374379"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"categories like '%math%'\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374379"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"categories rlike 'math'\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374379"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"categories rlike 'math|physics'\").count()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get licenses with 5 or more letters in the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            abstract|\n",
      "+--------------------+\n",
      "|  A fully differe...|\n",
      "|  We describe a n...|\n",
      "|  The evolution o...|\n",
      "|  We show that a ...|\n",
      "|  We study the tw...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = '''\n",
    "    select abstract from d_archive\n",
    "    where abstract regexp '\\(([A-Z][^!@#/+-_<>.,$%())]{5,})\\)'\n",
    "'''\n",
    "spark.sql(query2).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract statistics of the number of pages for unknown licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_page(line):\n",
    "    search = re.findall('\\d+ pages', line)\n",
    "    if search:\n",
    "        return int(search[0].split(' ')[0])\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "get_page('123 pages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_page(line)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('get_page_number', get_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+------------------+------+\n",
      "|               avg|min|max|               std|   cnt|\n",
      "+------------------+---+---+------------------+------+\n",
      "|15.991180538236561|  1| 99|17.168944606277094|352856|\n",
      "+------------------+---+---+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = '''\n",
    "    select avg(get_page_number(comments)) as avg,\n",
    "           min(get_page_number(comments)) as min,\n",
    "           max(get_page_number(comments)) as max,\n",
    "           std(get_page_number(comments)) as std,\n",
    "           count(1) as cnt \n",
    "    from   d_archive\n",
    "    where  license = 'unknown'\n",
    "    and    get_page_number(comments) != 0\n",
    "'''\n",
    "\n",
    "spark.sql(query3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b785a0a06e2d7a312a57a7dba8bbee97b75bb74680ea935274a48dc11f29425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
